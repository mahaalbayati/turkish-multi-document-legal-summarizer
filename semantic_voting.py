# -*- coding: utf-8 -*-
"""Semantic_voting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tAd7aiRw2ff2Vdtzn1AC6IJrWlEASJ95
"""

import pandas as pd
from sentence_transformers import SentenceTransformer, util
import torch
import numpy as np
from collections import defaultdict
import re

# Load dataset
df = pd.read_excel("multi_model_summaries.xlsx")

# Define the columns containing model-generated summaries and the reference summary
summary_columns = [
    "LED_Generated_Summary",
    "LONG_T5_Generated_Summary",
    "BART_Generated_Summary",
    "GPT-3.5_Generated_Summary"
]
reference_column = "Reference_Summary"

# === 1. Initialize the model ===
model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-mpnet-base-v2")

# === 2. Helper functions ===

def has_consecutive_match(a, b, min_consecutive=2):
    """Check if two sentences have at least 'min_consecutive' matching consecutive words"""
    a_words = a.lower().split()
    b_words = b.lower().split()

    if len(a_words) < min_consecutive or len(b_words) < min_consecutive:
        return False

    a_ngrams = set(zip(*[a_words[i:] for i in range(min_consecutive)]))
    b_ngrams = set(zip(*[b_words[i:] for i in range(min_consecutive)]))

    return len(a_ngrams & b_ngrams) > 0

def advanced_semantic_vote(sentences, similarity_threshold=threshold, min_votes=min_v):
    """
    Perform advanced semantic voting by clustering semantically similar sentences
    """
    if len(sentences) < 2:
        return sentences

    embeddings = model.encode(sentences, convert_to_tensor=True)
    sim_matrix = util.cos_sim(embeddings, embeddings)

    clusters = []
    used_indices = set()

    for i in range(len(sentences)):
        if i in used_indices:
            continue

        cluster = [i]
        for j in range(i+1, len(sentences)):
            if sim_matrix[i][j] >= similarity_threshold:
                cluster.append(j)

        if len(cluster) >= min_votes:
            clusters.append(cluster)
            used_indices.update(cluster)

    selected = []
    for cluster in clusters:
        cluster_sentences = [sentences[i] for i in cluster]
        selected.append(min(cluster_sentences, key=lambda x: len(x.split())))

    for i in range(len(sentences)):
        if i not in used_indices:
            selected.append(sentences[i])

    return selected

def select_best_sentences(ref_sentences, candidate_sentences, max_sentences=4):
    """
    Select the best candidate sentences based on reference alignment and semantic similarity
    """
    selected = []
    used_indices = set()

    ref_embeddings = model.encode(ref_sentences, convert_to_tensor=True)
    cand_embeddings = model.encode(candidate_sentences, convert_to_tensor=True)
    sim_matrix = util.cos_sim(ref_embeddings, cand_embeddings)

    for i, ref_sent in enumerate(ref_sentences):
        best_score = -1
        best_idx = -1

        for j in range(len(candidate_sentences)):
            if j in used_indices:
                continue

            text_match = has_consecutive_match(ref_sent, candidate_sentences[j])
            semantic_sim = sim_matrix[i][j].item()

            if text_match and semantic_sim > best_score:
                best_score = semantic_sim
                best_idx = j

        if best_idx != -1:
            selected.append(candidate_sentences[best_idx])
            used_indices.add(best_idx)

        if len(selected) >= max_sentences:
            break

    return selected, used_indices

# === 3. Main summarization function ===

def generate_voting_based_summary(row, max_sentences=max, min_sentence_words=min):
    """
    Generate a summary using semantic voting and alignment with the reference summary
    """
    ref = row[reference_column]
    if not isinstance(ref, str) or not ref.strip():
        return ""

    ref_sentences = [s.strip() for s in ref.split('.')
                     if len(s.strip().split()) >= min_sentence_words]

    all_generated = []
    for col in summary_columns:
        text = row[col]
        if isinstance(text, str) and text.strip():
            sentences = [s.strip() for s in text.split('.')
                         if len(s.strip().split()) >= min_sentence_words]
            all_generated.extend(sentences)

    if not all_generated or not ref_sentences:
        return ""

    voted_sentences = advanced_semantic_vote(all_generated)
    selected, used = select_best_sentences(ref_sentences, voted_sentences, max_sentences)

    if len(selected) < max_sentences:
        remaining = [s for i, s in enumerate(voted_sentences) if i not in used]
        if remaining:
            ref_embed = model.encode(ref, convert_to_tensor=True)
            remaining_embeds = model.encode(remaining, convert_to_tensor=True)
            sim_scores = util.cos_sim(ref_embed, remaining_embeds)[0]

            needed = min(max_sentences - len(selected), len(remaining))
            top_indices = torch.topk(sim_scores, k=needed).indices
            selected.extend([remaining[i] for i in top_indices])

    summary = '. '.join(selected[:max_sentences])
    summary = re.sub(r'\.+', '.', summary).strip()
    if summary and not summary.endswith('.'):
        summary += '.'

    return summary

# === 4. Apply the summarization and save results ===

df["Voting_Matched_Summary"] = df.apply(generate_voting_based_summary, axis=1)
output_columns = ["Reference_Summary"] + summary_columns + ["Voting_Matched_Summary"]
df[output_columns].to_excel("voting_based_summaries.xlsx", index=False)
print("âœ… Summaries generated successfully using advanced semantic voting.")