# -*- coding: utf-8 -*-
"""weighted_based_rougescores.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NyNQY1dyVzoKjxy2B48K8ch2bqeSjMY-
"""

import pandas as pd
from collections import defaultdict
from rouge_score import rouge_scorer
from sentence_transformers import SentenceTransformer, util
from zemberek import TurkishSentenceExtractor, TurkishMorphology

# === 1. Load the dataset ===
df = pd.read_excel("/content/multi_model_summaries.xlsx")

# === 2. Define model-generated summary columns and the reference summary ===
summary_columns = [
    "LED_Generated_Summary",
    "LONG_T5_Generated_Summary",
    "BART_Generated_Summary",
    "GPT-3.5_Generated_Summary"
]
reference_column = "Reference_Summary"

# === 3. Compute model weights based on ROUGE-2 scores ===
print("Calculating model weights based on ROUGE-2...")
scorer = rouge_scorer.RougeScorer(['rouge2'], use_stemmer=True)
model_weights = {}

for col in summary_columns:
    summaries = df[col].astype(str).tolist()
    references = df[reference_column].astype(str).tolist()

    total_f1 = 0.0
    for summary, reference in zip(summaries, references):
        scores = scorer.score(reference, summary)
        total_f1 += scores['rouge2'].fmeasure

    avg_f1 = total_f1 / len(summaries)
    model_weights[col] = avg_f1
    print(f"{col}: {avg_f1:.4f}")

# Normalize weights
total_weight = sum(model_weights.values())
model_weights = {k: v/total_weight for k, v in model_weights.items()}

# === 4. Initialize sentence embedding model and Zemberek tools ===
sentence_model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
morphology = TurkishMorphology.create_with_defaults()
extractor = TurkishSentenceExtractor()

def split_turkish_sentences(text):
    """Split Turkish text into sentences using Zemberek"""
    if not isinstance(text, str) or not text.strip():
        return []
    return [str(s) for s in extractor.from_paragraph(text)]

# === 5. Hybrid ensemble summarization function ===
def hybrid_ensemble_summary(row, top_k=4, similarity_threshold=0.85, model_weight=0.6):
    sentence_scores = defaultdict(float)

    for model in summary_columns:
        if not isinstance(row[model], str):
            continue
        sentences = split_turkish_sentences(row[model])

        for sentence in sentences:
            if isinstance(row[reference_column], str):
                sentence_score = scorer.score(row[reference_column], sentence)['rouge2'].fmeasure
            else:
                sentence_score = 0.0
            combined_score = (model_weight * model_weights[model] +
                              (1 - model_weight) * sentence_score)
            sentence_scores[sentence] += combined_score

    if not sentence_scores:
        return ""

    all_sentences = list(sentence_scores.keys())
    embeddings = sentence_model.encode(all_sentences, convert_to_tensor=True)
    cosine_scores = util.pytorch_cos_sim(embeddings, embeddings)

    used_indices = set()
    final_sentences = []

    for i in range(len(all_sentences)):
        if i in used_indices:
            continue
        cluster = [i]
        for j in range(i+1, len(all_sentences)):
            if cosine_scores[i][j] >= similarity_threshold:
                cluster.append(j)
        used_indices.update(cluster)
        best_in_cluster = max(cluster, key=lambda x: sentence_scores[all_sentences[x]])
        best_sentence = all_sentences[best_in_cluster]
        final_sentences.append((best_sentence, sentence_scores[best_sentence]))

    top_sentences = sorted(final_sentences, key=lambda x: x[1], reverse=True)[:top_k]

    ordered_sentences = []
    for model in summary_columns:
        if not isinstance(row[model], str):
            continue
        model_sentences = split_turkish_sentences(row[model])
        for sent in model_sentences:
            if sent in [s[0] for s in top_sentences] and sent not in ordered_sentences:
                ordered_sentences.append(sent)
                if len(ordered_sentences) >= top_k:
                    break
        if len(ordered_sentences) >= top_k:
            break

    if not ordered_sentences:
        return ""

    # Clean trailing dots from each sentence
    cleaned_sentences = [s.rstrip('.').strip() for s in ordered_sentences[:top_k]]

    # Concatenate sentences with a single period
    final_summary = '. '.join(cleaned_sentences) + '.' if cleaned_sentences else ""

    # Remove extra spaces before periods
    final_summary = final_summary.replace(' .', '.').replace('..', '.')

    return final_summary

# === 6. Apply the summarization function to each row ===
print("\nGenerating hybrid ensemble summaries...")
df["Hybrid_weighted_Ensemble_Summary"] = df.apply(hybrid_ensemble_summary, axis=1)

# === 7. Save the results ===
output_path = "hybrid_weighted_ensemble_summaries.xlsx"
df[["Hybrid_Ensemble_Summary"] + summary_columns + [reference_column]].to_excel(output_path, index=False)
print(f"\nSummaries saved to: {output_path}")

# === 8. Optional performance evaluation ===
print("\nEvaluating hybrid weighted summary performance:")
hybrid_scores = []
references = df[reference_column].astype(str).tolist()
hybrid_summaries = df["Hybrid_weighted_Ensemble_Summary"].astype(str).tolist()

for ref, hyp in zip(references, hybrid_summaries):
    scores = scorer.score(ref, hyp)
    hybrid_scores.append(scores['rouge2'].fmeasure)

avg_hybrid_score = sum(hybrid_scores) / len(hybrid_scores)
print(f"Average ROUGE-2 score for hybrid summary: {avg_hybrid_score:.4f}")