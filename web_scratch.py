# -*- coding: utf-8 -*-
"""web_scratch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1szSSK7UV66BVOmczZlkWB7sQnWkvjXJz
"""

import requests
import json
import time
from bs4 import BeautifulSoup

mydocuments = []
path = r"your path"

def getDocumentDetail(documentId):
    URL = "url?id="+documentId
    headers={
        'content-type': 'application/json',
        'User-Agent':'mozila/5.0/'
    }

    documentJson=requests.get(URL,headers=headers,data=json.dumps(body)).json()['data']
    print("**************")
    print("Document: "+documentId)
    # startIndex = documentJson.find("<p align=\"justify\"><font face=\"Verdana\" size=\"2\">")
    startIndex = documentJson.find("<font face=\"Verdana\" size=\"2\">")
    finishIndex = documentJson.find("<br><br><br><br>")
    decision = documentJson[startIndex+30:finishIndex]
    clean_text = BeautifulSoup(decision, 'lxml').get_text().strip()
    mydocuments.append(clean_text)
    with open(path, 'a', encoding='utf-8') as file:
        file.write(clean_text + "\n")


pageSize = 10
searchTerm = "Term"
URL = "url"
body= {"data": { "aranan": searchTerm, "arananKelime": searchTerm, "pageSize": pageSize, "pageNumber": 1 }};
headers={
    'content-type': 'application/json',
    'User-Agent':'mozila/5.0/'
}
jsonData=requests.post(URL,headers=headers,data=json.dumps(body)).json()

recordCount = jsonData['data']['recordsTotal']
pageCount = jsonData['data']['draw'] + 1

for i in range(75,80):
    time.sleep(30)
    URL = "url"
    body= {"data": { "aranan": searchTerm, "arananKelime": searchTerm, "pageSize": pageSize, "pageNumber": i }};
    headers={
        'content-type': 'application/json',
        'User-Agent':'mozila/5.0/'
    }
    jsonData=requests.post(URL,headers=headers,data=json.dumps(body)).json()
    documents  = jsonData['data']['data']

    for doc in documents:
        time.sleep(90)
        documentId = doc['id']
        getDocumentDetail(documentId)